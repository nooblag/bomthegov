#!/bin/bash

# bomthegov
# fetch radar and satellite images from bom.gov.au and build timelapse videos from collected data


## set up environment
  this_name='bomthegov'
  this_version='0.1.1'
  this_name_and_version="${this_name} - Version ${this_version}"
  this_name_and_version_and_author="${this_name_and_version} - by @nooblag"
  fullpath_and_filename="$(readlink --canonicalize "${0}")"
  working_directory="$(dirname "${fullpath_and_filename}")"
  # name of this file only: ${0##*/}
  # relative path and file name: ${0}
  # full path and file name: ${fullpath_and_filename}
  # full path only: ${working_directory}

# references for mapping exit codes
  # exit_1='software or file dependency fail'
  # exit_2='problem working with paths'
  # exit_3='failure related to user input'
  # exit_4='failure fetching remote data or networking error'
  # exit_5='file lock error'
  # exit_6='interrupted'

# first determine if script is running interactively or as a scheduled job by checking for an interactive tty
# if we get something other than zero, the display (fd0) is not open = this is running as an automated job
! [[ -t 0 ]] && cron=1 && process='no-tty: '

# setup debug logging
logfile="${working_directory}/.xtrace.log"
  # if the debug config setting file exists, switch on logging
  if [[ -e "${working_directory}/.config/debug" ]]; then
    # if the logfile exists and is larger than 6 megabytes, quietly rotate it
    find "${logfile}" -size +6M -exec mv --force "${logfile}" "${logfile}.1" \; > /dev/null 2>&1
    # now handle log file headings
    # get the pid of this instance
    pid=${$}
    # return the command name that invoked this script using `ps`
    # we expect bash, but useful to detect if problems may be arising from the use of other unsupported shells
    # $$ is the process id of the script that is being run
    # `--quick-pid` to only report on process id $$ and ignore other `ps` filtering
    # `--format comm=` omits default headers and sets output to return 'command name only'
    process+="$(ps --quick-pid ${pid} --format comm=) "
    # append the name and path of here
    process+="${0}"
    # if any arguments have been passed here, append them to the line too
    [[ -n ${*} ]] && process+=" ${*}"
    # the format is now: [bomthegov] [date/time of initialisation] [if tty or not] [shell] [the name/path of this] [args]
    # print the appropriate heading
    if [[ -s "${logfile}" ]]; then
      # log already exists so bump with some whitespace before logging this session
      printf '\n\n\n\n\n\n\n\n%s --- %s --- %s ---\n\n' "--- ${this_name}" "$(date) [${pid}]" "${process}" >> "${logfile}"
    else
      # log doesn't exist, so create it with the same heading structure as above, just without the leading padding
      printf '%s --- %s --- %s ---\n\n' "--- ${this_name}" "$(date) [${pid}]" "${process}" > "${logfile}"
    fi
    # now actually set up the process to write xtrace and stderr output to a log file for debugging
    # the file descriptors for stdin, stdout, and stderr are 0, 1, and 2, respectively ;)
    # so progress through how we want to handle each:
      # [stderr]
      # use `tee` to display stderr on the console as normal, but also write those errors to the logfile
      # note the format of spaces here: 2> as direction for stderr, *then* the syntax of ">(process substitution as if it were a file)"
      exec 2> >(tee --append "${logfile}")
      # [xtrace]
      # file descriptors 3 through 9 are not set, so use the last fd, 9, to write anything sent there to the log file only
      # note the *lack of spaces* here to mean fd9 *appends* to file ;)
      exec 9>>"${logfile}"
    # now tell bash to write its 'xtrace' output to fd9 which we've opened above
    BASH_XTRACEFD=9
    # rewrite $P4 to modify the console prompt to prepend the time and line number of this script that is currently executing at run time
    # note the use of single quotes here because we don't want parameter expansion to happen yet, we want to pass the vars to `exec` to expand at the moment the prompt writes
    # display format is [HOUR:MIN:SEC.NANOSEC] LINENO: ...
    PS4=' [$(date +%H:%M:%S.%N)] [${pid}] ${LINENO}: '
    # finally, turn on bash 'debug' which makes all of the above ultimately meaningful
    set -o xtrace
  fi

# this script assumes a debian-based system, so quietly check this system is supported before doing anything further
# use -v to do verbose binaries search, -p to use default value(s) for PATH
if ! command -vp dpkg > /dev/null 2>&1; then
  printf '\n%s\n\n' "Sorry, this script is only supported on Debian-based operating systems."
  printf '%s %s.\n\n' "It looks like you're using" "$(lsb_release --description --short)"
  exit 1
fi

# check if the following dependent software packages are ready to go
# `gawk` is used to ensure `awk` from `/usr/bin/awk` is GNU awk and not the older `mawk` like it is in most Debian-based distros except Mint
dependencies=(git gawk wget curl imagemagick ffmpeg)
for package in "${dependencies[@]}"; do
  # quietly check with package manager if required software is installed
  dpkg --status "${package}" > /dev/null 2>&1 || failed+=("${package}")
done
# if $failed array contains something, then report what is missing
if [[ "${#failed[@]}" -ne 0 ]]; then
  printf '\n%s\n\n' "The following packages in yellow are missing, but can be installed using:"
  # use `tput` to set the colour
  printf '%s%s' "sudo apt install" "$(tput setaf 3)"
  # iterate over each missing program in 'failed' array
  for package in "${failed[@]}"; do
    printf ' %s' "${package}"
  done
  # reset colour
  printf '%s\n\n' "$(tput sgr0)"
  # stop here and exit with error code 1
  exit 1
fi

# check if the following dependent bundled files exist and have contents
required_files=(
  "${working_directory}/.data/desc.csv"
  "${working_directory}/.etc/merge-lists.awk"
  "${working_directory}/.config/ImageMagick/policy.xml"
)
for file in "${required_files[@]}"; do
  [[ ! -s "${file}" ]] && failed+=("${file}")
done
# if not running 'update' (to fix the problem of missing files)
# and $failed array contains something, then report what is missing and what to do to fix
if [[ "${1}" != 'update' ]] && [[ "${#failed[@]}" -ne 0 ]]; then
  printf '\n%s\n\n' "There is a problem with bundled file(s) that ${this_name} needs."
  # iterate over each missing program in 'failed' array
  for file in "${failed[@]}"; do
    printf '%s %s %s %s\n' "Missing:" "$(tput setaf 3)" "${file}" "$(tput sgr0)"
  done
  # stop here and exit with error code
  printf '\n%s\n%s\n\n' "Please reinstall ${this_name} by running:" "  'bash ${0} update'"
  exit 1
fi



## functions

init() {
  # ensure we have a path for image storage available
  mkdir --parents "${working_directory}/.tmp" "${working_directory}/images" || exit 2

  # set a temporary storage for this session
  tmp="$(mktemp --directory --tmpdir="${working_directory}/.tmp" .session-XXXXXXXXXXXXXXXX)"

  # set a trap to ensure garbage collection from now on
  trap 'rm --force --recursive "${tmp}"' SIGINT SIGTERM EXIT
  # set a trap to ensure cursor is reset if interrupted by user and everything stops
  # final errexit will also trip garbage collection EXIT trap above
  trap 'tput cnorm && echo "   " && exit 6' SIGINT

  # set the temporary storage as the working directory
  cd "${tmp}" || exit 2

  # export some variables to setup specific environments for dependencies
    # [less]
      # set up a 'global' prompt to use everywhere, including in help docs
      less_prompt="--Use arrows to scroll or '/' to search, press 'Q' when finished--"
      # set up `less` to use custom prompt and mouse, etc
      export LESS="--quit-if-one-screen --ignore-case --mouse --prompt=${less_prompt}"
      # ensure security for `less` is set to disallow shell commands, piping, editing, log files, and tab completion inside `less`
      export LESSSECURE=1
    # [imagemagick]
      # specify the path where imagemagick should look for policy.xml (bug fix to increase memory limit for converting large satellite images)
      export MAGICK_CONFIGURE_PATH="${working_directory}/.config/ImageMagick/"
}

display_about() {
  cat <<-end_cat

	${this_name_and_version_and_author}

	A tool to fetch radar or satellite images at set intervals from the Australien [sic]
	Bureau of Meteorology (BOM) public archive, and build simple timelapse videos from
	collected images.

	end_cat
}

display_help() {
  # display the about information first
  display_about
  # then explain how to use this thing, with an example
  cat <<-end_cat

	Usage: bash ${0} <option>

	Available options:
	  satellite     Collect images from a satellite.
	  radar         Collect images from a radar.
	  timelapse     Generate a timelapse video from collected images.
	  reset         Delete all collected images, and archives.
	  update        Download and apply latest version of ${this_name}.
	  debug         Turn on/off code debug logging.
	  version       Display version information.
	  help          Display this help message.

	For example:
	  'bash ${0} satellite'
	will display help on fetching image sets from a satellite.

	end_cat
}

display_satellite_help() {
  cat <<-end_cat

	Usage: bash ${0} satellite <option>

	Available options:
	  list          Fetch a list of available satellite IDs.
	  <id>          Start collecting images of <id> satellite.

	  <id> <HH:MM>  Collect a specific 24hr time from <id> satellite images. Time is UTC.

	                Time format is HH:MM. So for example, a value of '02:30' will collect
	                 any images from 2:30am only.

	                Single character globbing (a question mark) can be used to wildcard minutes.
	                 For example, '09:2?' will extract images from *any* minute inside twenty
	                 past nine; while '20:?4' will extract any image inside any ten minute range
	                 ending with 4 (i.e. 04, 14, 24, 34, 44, and 54) inside eight o'clock.
	                Double question marks can also be used to extract for the whole hour. So for
	                 example, '16:??' will match all images available inside 4pm only.

	                *** Please note *** the "delete time" (DelT) for some satellite images is
	                 less than 24hrs, so this setting is mostly only useful when ${this_name}
	                 is running as an automated job (for example, a cronjob), as a glob pattern
	                 outside DelT will not return any matches, and hence capture no images. You
	                 can run the 'list' option from above to get data on each satellite's DelT.

	  help          Display this help message.

	For example:
	  'bash ${0} satellite IDE00435'
	will start collecting images from the Himawari-8 satellite.

	end_cat
}

display_radar_help() {
  cat <<-end_cat

	Usage: bash ${0} radar <option>

	Available options:
	  list          Fetch a list of available radar IDs.
	  <id>          Start collecting images of <id> radar.

	  <id> <HH:MM>  Collect a specific 24hr time from <id> radar images. Time is UTC.

	                Time format is HH:MM. So for example, a value of '02:30' will collect
	                 any images from 2:30am only.

	                Single character globbing (a question mark) can be used to wildcard minutes.
	                 For example, '09:2?' will extract images from any minute inside twenty
	                 past nine; while '20:?4' will extract any image inside any ten minute range
	                 ending with 4 (i.e. 04, 14, 24, 34, 44, and 54) inside eight o'clock.
	                Double question marks can also be used to extract for the whole hour. So for
	                 example, '16:??' will match all images available inside 4pm.

	                *** Please note *** the "delete time" (DelT) for some radar images is less
	                 than 2hrs, so this setting is mostly only useful when ${this_name} is running
	                 as an automated job (for example, a cronjob), as a glob pattern outside of
	                 DelT will not return any matches, and hence capture no images. You can run
	                 the 'list' option from above to get data on each radar's DelT.

	  help          Display this help message.

	For example:
	  'bash ${0} radar IDR421'
	will start collecting images from the Giles WA rain radar.

	end_cat
}

display_timelapse_help() {
  cat <<-end_cat

	Usage: bash ${0} timelapse <option>

	Available options:
	  list          Display a list of collected image sets.
	  <id>          Make a timelapse video for a specific radar or satellite ID.
	  help          Display this help message.

	end_cat
}

display_debug_help() {
  cat <<-end_cat

	Usage: bash ${0} debug <option>

	Available options:
	  on            Turn on code debugging log (default). The log is saved in .data folder.
	  off           Turn off logging and erase any existing logs.

	end_cat
}

display_version() {
  cat <<-end_cat
	${this_name}
	Version ${this_version}

	end_cat
  # now display license amble from bundled file
  cat "${working_directory}/license.md"
}

display_flock_error() {
  # $1 should be the exit code argument passed to this function
  # values we expect are: 4 if `wget` fails; 5 if `flock` encounters a conflict with file locking
  # 4 is set explicitly with the `wget` line inside `flock`
  # 5 is set explicitly on the `flock` line with --conflict-exit-code 5
  # so if we encounter exit code '5' meaning `flock` conflict, display an error message, otherwise fail and stop silently
  if [[ ${1} -eq 5 ]]; then
    printf '\n%s\n%s\n%s\n\n' "*** File lock error ***" "An identical fetch process is already running." "Stopping."
  fi
  # now stop with whatever exit code we encountered
  exit "${1}"
}

display_spinner() {
  # set up a spinner for long-expected processes so the user can visually see the script is still working away
  # takes the pid of the process passed to the background and captured in $1, and displays a spinner until that process completes
  # solution derived with thanks to @david_rankin (https://stackoverflow.com/questions/47234947)
  if [[ ${cron} -ne 1 ]]; then
    local proc="${1}"
    local delay="0.15"
    # get the cursor out of the way, by hiding it
    tput civis
    # do the spinning as long as the process is active
    while [[ -d /proc/${proc} ]]; do
      printf '\033[s\033[u[/]\033[u'; sleep "${delay}"
      printf '\033[s\033[u[â€”]\033[u'; sleep "${delay}"
      printf '\033[s\033[u[\]\033[u'; sleep "${delay}"
      printf '\033[s\033[u[|]\033[u'; sleep "${delay}"
    done
    # return to normal by wiping out the spinner's combined character length (3 spaces)
    printf '\033[s\033[u   \033[u\033[0m'
    # restore the cursor
    tput cnorm
    return 0
  fi
  # to use the spinner, send a command to the background, capture its pid, then set the spinner to run while 'listening' for that task to finish
  # example, using `sleep 2`
    # sleep 2 & pid=${!}
    # display_spinner ${pid}
    # wait ${pid}
}

display_pretty_timer(){
  # convert provided seconds in $1 to a prettification of days, hours, minutes, seconds
  # thanks to ideas by @nikolay_sidorov and https://www.shellscript.sh/tips/hms/
  local parts seconds D H M S D_tag H_tag M_tag S_tag
  seconds=${1:-0}
  # all days
  D=$((seconds / 60 / 60 / 24))
  # all hours
  H=$((seconds / 60 / 60))
  H=$((H % 24))
  # all minutes
  M=$((seconds / 60))
  M=$((M % 60))
  # all seconds
  S=$((seconds % 60))

  # set up "x day(s), x hour(s), x minute(s) and x second(s)" language
  [[ "$D" -eq "1" ]] && D_tag="day" || D_tag="days"
  [[ "$H" -eq "1" ]] && H_tag="hour" || H_tag="hours"
  [[ "$M" -eq "1" ]] && M_tag="minute" || M_tag="minutes"
  [[ "$S" -eq "1" ]] && S_tag="second" || S_tag="seconds"

  # for parts above that exist, parts into an array for sentence formatting
  parts=()
  [[ "$D" -gt "0" ]] && parts+=("$D $D_tag")
  [[ "$H" -gt "0" ]] && parts+=("$H $H_tag")
  [[ "$M" -gt "0" ]] && parts+=("$M $M_tag")
  [[ "$S" -gt "0" ]] && parts+=("$S $S_tag")

  # construct the sentence
  result=''
  length_of_parts=${#parts[@]}
  for ((currentpart = 0; currentpart < length_of_parts; currentpart++)); do
    result+="${parts[$currentpart]}"
    # if current part is not the last portion of the sentence, append a comma
    [[ "$currentpart" -ne $((length_of_parts - 1)) ]] && result+=", "
    # if current part will be the last part of the sentence, say 'and'
    [[ "$currentpart" -eq $((length_of_parts - 2)) ]] && result+="and "
  done
  printf '%s\n' "${result}"
}

get_satellite_list() {
  # dump entire satellite directory
  # use 'spidering' to not download anything and just get .listing file of ftp directory
  # also set lots of tries to handle when bom is busy and ftp seems to timeout a lot
  wget --quiet --spider --no-remove-listing --timeout=30 --tries=30 --random-wait 'ftp://ftp.bom.gov.au/anon/gen/gms/' || return 4
  # pattern match the list to return only satellite IDs (IDE), and only match IDs that contain TIF or JPG files
  # then "sub(regexp, replacement, target)" to strip the rest of the line away (by replacing it with nothing), to "print only the ID part"
  gawk '/IDE.*\.tif|\.jpg/ { sub("\\..*", "", $NF); print $NF }' .listing | sort --unique > satellite-IDs.list
}

get_radar_list() {
  wget --quiet --spider --no-remove-listing --timeout=30 --tries=30 --random-wait 'ftp://ftp.bom.gov.au/anon/gen/radar/' || return 4
  # pattern match radar IDs, only matching IDs that contain PNG files
  gawk '/IDR.*\.png/ { sub("\\..*", "", $NF); print $NF }' .listing | sort --unique > radar-IDs.list
}

get_timelapse_list() {
  # find directories in image storage that have content in them and generate a list of what paths might be usable
  # exclude hidden directories by excluding paths that start with dot, i.e. -not -path '*/.*'
  find "${working_directory}/images" -mindepth 2 -type d -not -path '*/.*' -not -name 'layers' -not -name 'legend' -not -empty -print | sort --unique > image-paths.list
  # if list file size is zero, then we have nothing to work with
  if ! [[ -s image-paths.list ]]; then
    printf "%s\n\n" "No image sets found. Try collecting some images?"
    printf '%s\n\n' "If you need help, try: 'bash ${0} help'"
    exit 3
  fi
  # file above contains our paths, but now also make a pretty list for displaying
  # traverse the list and clean off the paths from each ID
  while read -r file; do
    # pattern match off everything until after last slash with parameter expansion and build new list
    echo "${file##*/}" >> timelapse-IDs.list
  done < image-paths.list
  # pretty display
  printf '\n\n%s\n\n' "The following IDs seem to have possible collected image data ready to timelapse:"
  merge_lists "${working_directory}/.data/desc.csv" 'timelapse-IDs.list' prettify && printf '\n'
}

merge_lists() {
  # match found IDs using `awk` from a CSV file that contains rows of descriptive data about known IDs
  # merge the two data sets and then prettify the results to display them
  # can find/replace on both satellite or radars lists
  local csv_file="${1}"
  local list_file="${2}"
  # pass $3 to `awk` to use in its test to determine if it should prettify display or not
  # load gawk script from .etc
  gawk --field-separator=',' --file="${working_directory}/.etc/merge-lists.awk" --assign=prettify="${3}" "${csv_file}" "${list_file}"
}

strict_test_satellite_id() {
  local user_input="${1}"
  # satellite IDs should start with "IDE" and then 5 numbers (8 characters max in total)
  # if we match that format, return 0 for success, else return 3 for "problem with user input" code
  [[ "${user_input}" =~ ^IDE[0-9]{5}$ ]] && id_type='satellite' && return 0 || return 3
}

strict_test_radar_id() {
  local user_input="${1}"
  # radar IDs should start with 'IDR' and contain at least 3 alpha/numeric characters, max of 5 (8 characters max in total)
  # expect A B C D or I
  [[ "${user_input}" =~ ^IDR[0-9|A-D|I]{3,5}$ ]] && id_type='radar' && return 0 || return 3
}

handle_user_input() {
  local context="${1}" # $1 being the arg passed to this function, which will be the matching arg "radar" or "satellite" or "timelapse" the user has typed
  # $2 is unsanitised user input
  # accept input with lowercase letters, which is good for lazy typing, but bump everything in $2 to uppercase with ^^ parameter expansion
  local user_input="${2^^}"
  # we need uppercase sanitised input for strict `grep` checking and also correct FTP file pattern matching throughout *** ! important ! ***
  # test $2 thoroughly, to both see what we have is an expected format in its context, to avoid trouble as much as possible because:
  # user input here is used to build paths and filenames and so on!
  case "${context}" in
    'satellite')
      if strict_test_satellite_id "${user_input}"; then
        id="${user_input}"
      else
        printf "\n'%s' %s\n%s\n\n%s\n" "${user_input}" "is not a valid satellite ID." "Expected ID is 8 alpha-numeric characters, starting with 'IDE'." "For example: IDE00135"
        printf '%s\n\n' "Try 'bash ${0} satellite list' to display a list of available IDs."
        exit 3
      fi
    ;;
    'radar')
      if strict_test_radar_id "${user_input}"; then
        id="${user_input}"
      else
        printf "\n'%s' %s\n%s\n\n%s\n" "${user_input}" "is not a valid radar ID." "Expected ID is 6 to 8 alpha-numeric characters, starting with 'IDR'." "For example: IDR034"
        printf '%s\n\n' "Try 'bash ${0} radar list' to display a list of available IDs."
        exit 3
      fi
    ;;
    'timelapse')
      if strict_test_radar_id "${user_input}" || strict_test_satellite_id "${user_input}"; then
        id="${user_input}"
      else
        printf "\n'%s' %s\n" "${user_input}" "is not a valid ID."
        printf '%s\n\n' "Try 'bash ${0} timelapse list' to display a list of available IDs."
        exit 3
      fi
    ;;
  esac
}

handle_question() {
  # display a question and return zero status if 'Y' or 'y' matched, which will continue
  # $1 is the contents of question passed to this function
  # i.e. usage: handle_question "Continue?" && dostuff
  read -r -p "${1} [Y/n] " answer
  [[ ${answer} == 'Y' || ${answer} == 'y' ]] && return 0 || return 1
}

handle_cron_sleep() {
  # if this instance is running as a cronjob, introduce a large randomised wait of up to 60 seconds
  # this is inserted before bulk fetches even commence when running as a cronjob, to:
  # 1) distribute initial server load at remote end at common cron start times (on the hour, for example)
  # 2) avoid network/disk congestion at local end for similar conditions, and
  # 3) atomise the initialisation time of multiple concurrent cronjobs at share the same pattern
  # e.g. if multiple jobs start at every 10 min interval (like for satellites) we won't get as dramatic i/o inrush
  [[ "${cron}" -eq 1 ]] && sleep "$(shuf --input-range 0-60 --head-count 1)"
}

handle_satellite_images() {
  case "${2}" in
    'list')
      init
      printf '%s' "Fetching satellite list... "
      # run the function to fetch the list, push it to the background, and display spinner while we wait
      get_satellite_list & pid=${!}
      display_spinner ${pid}
      wait ${pid}; get_list_status=${?}
      if [[ ${get_list_status} -eq 0 ]]; then
        # getting list was a success, so pop in some pretty empty space
        printf '\n\n'
      else
        printf '%s\n' 'failed. Is the Internet connection up?'
        exit 4
      fi
      # pretty-display the data in nice columns, and pipe to `less` to handle scrolling
      merge_lists "${working_directory}/.data/desc.csv" 'satellite-IDs.list' prettify | less
      printf '\n'
    ;;

    ''|'help')
      # no option given, so display help
      # or help explicitly asked for
      display_satellite_help
    ;;

    *)
      init
      # passed variable user input here
      # run sanitation and formatting tests
      handle_user_input "${1}" "${2}" # $2 being unsanitised user input from command line
      # user input checks passed
      # set stopwatch to keep track of total run time for fetching, starting from now
      timer_start=$(date +%s)
      # introduce a large randomised wait before proceeding if this instance is running as a cron job
      handle_cron_sleep
      # now attempt to fetch what looks like a valid satellite ID
      printf '\n%s' "Attempting to fetch ${id} satellite images: "
      # ensure we have recent list first
      get_satellite_list & pid=${!}
      display_spinner ${pid}
      wait ${pid}; get_list_status=${?}
      if [[ ${get_list_status} -ne 0 ]]; then
        printf '%s\n' 'failed. Is the Internet connection up?'
        exit 4
      fi
      # is the ID on the list?
      if ! grep --quiet --fixed-strings "${id}" --line-regexp satellite-IDs.list; then
        printf '%s\n' 'failed.'
        printf "\n'%s' %s\n%s\n\n" "${id}" "ID could not be found as an available satellite image set." "Are you sure the ID is correct?"
        printf '%s\n\n' "Try 'bash ${0} satellite list' to display a list of available IDs."
        exit 3
      else
        # got the list and the ID exists, everything fine, add some pretty empty space
        printf '\n\n'
      fi

      # finished user input tests, so we have something to work with
      # ensure target paths exist and prepare to fetch
      mkdir --parents "${working_directory}/images/satellite/${id}" || exit 2
      cd "${working_directory}/images/satellite/${id}/" || exit 2

      # if we have a valid HH:MM globbing argument in ${3}, narrow the `wget` glob to that
      if [[ "${3}" =~ ^([01][0-9]|2[0-3]):([0-5][0-9]|[0-5]\?|\?[0-9]|\?\?)$ ]]; then
        # wrap `wget` in `flock` to lock the working directory so we don't get race condition when running this as a cronjob
        # if we get network problems with `wget`, its exit code should be 4 (in the wrapped flock command), otherwise if we encounter a problem with `flock`, exit 5
        # pass the `flock` exit code to display_flock_error() in order to either show a pretty message if encountering parallel fetching, otherwise fail silently
        # reject any "temporary" files, as in this context, these are images currently being written to disk at the origin and are incomplete
        # remove colon from globbing arg user input by using '//' parameter expansion
        # *** ! *** `wget` is weird because it writes file download progress to stderr, so explicitly redirect that here to stdout *** ! ***
        printf '%s %s %s\n\n' "Glob narrowed to select images from" "${3}" "UTC only."
        # now actually do the fetching
        flock --conflict-exit-code 5 --nonblock --exclusive --no-fork "${working_directory}/images/satellite/${id}" --command " \
          2>&1 wget --quiet --show-progress --progress=bar:force:noscroll --timestamping --continue --timeout=30 --tries=30 --random-wait --reject=tmp \
          ftp://ftp.bom.gov.au/anon/gen/gms/${id}.[0-9]*${3//:}.??? || exit 4" || display_flock_error $?
      else
        # sleep another random moment if we're running as a cronjob, before doing a bulk fetch
        handle_cron_sleep
        # download all images that start with ID using wildcard glob and 3x file extension characters
        # filename pattern on bom server is ID.YYYYMMDDHHMM, so match ID.[digits] only (to not match 'ID.radar' files for IDE00135 for instance)
        # this will traverse and fetch existing archive (i.e. whatever bom keeps on the server for 24 hours, for example)
        # *** ! *** `wget` is weird because it writes file download progress to stderr, so explicitly redirect that here to stdout *** ! ***
        # determine first if this is running as a cronjob, because if so, also introduce randomised wait times between each file here for a bulk fetch
        if [[ "${cron}" -eq 1 ]]; then
          # running as cron, introduce a randomised 0.5 to ~5.5 second wait between each file
          # satellite images are quite large, so bulk transfers of whole image sets before each "delete time" at remote end (DelT) are the most resource intensive for bom
          printf '%s\n\n' "*** Running as a cronjob, so going slow ***"
          # now do the fetching
          flock --conflict-exit-code 5 --nonblock --exclusive --no-fork "${working_directory}/images/satellite/${id}" --command " \
            2>&1 wget --quiet --show-progress --progress=bar:force:noscroll --timestamping --continue --timeout=30 --tries=30 --wait=5 --random-wait --reject=tmp \
            ftp://ftp.bom.gov.au/anon/gen/gms/${id}.[0-9]*.??? || exit 4" || display_flock_error $?
        else
          # interactively running, so fetch at a pace that isn't slowed down
          flock --conflict-exit-code 5 --nonblock --exclusive --no-fork "${working_directory}/images/satellite/${id}" --command " \
            2>&1 wget --quiet --show-progress --progress=bar:force:noscroll --timestamping --continue --timeout=30 --tries=30 --random-wait --reject=tmp \
            ftp://ftp.bom.gov.au/anon/gen/gms/${id}.[0-9]*.??? || exit 4" || display_flock_error $?
        fi
      fi
      # completed successfully, stop timer and display total runtime
      timer_stop=$(date +%s)
      printf '\n%s\n\n' 'Completed successfully.'
      printf '%s\n\n' "Total fetching time was $(display_pretty_timer $((timer_stop-timer_start)))."
    ;;
  esac
}

handle_radar_images() {
  case "${2}" in
    'list')
      init
      printf '%s' "Fetching radar list... "
      # run the function to fetch the list, push it to the background, and display spinner while we wait
      get_radar_list & pid=${!}
      display_spinner ${pid}
      wait ${pid}; get_list_status=${?}
      if [[ ${get_list_status} -eq 0 ]]; then
        # getting list was a success, so pop in some pretty empty space
        printf '\n\n'
      else
        printf '%s\n' 'failed. Is the Internet connection up?'
        exit 4
      fi
      # pretty-display the data in nice columns, and pipe to `less` to handle scrolling
      merge_lists "${working_directory}/.data/desc.csv" 'radar-IDs.list' prettify | less
      printf '\n'
    ;;

    ''|'help')
      # no option given, so display help
      # or help explicitly asked for
      display_radar_help
    ;;

    *)
      init
      # passed variable user input here
      # run sanitation and formatting tests
      handle_user_input "${1}" "${2}" # $2 being unsanitised user input from command line
      # user input checks passed
      # set stopwatch to keep track of total run time for fetching, starting from now
      timer_start=$(date +%s)
      # introduce a large randomised wait before proceeding if this instance is running as a cron job
      handle_cron_sleep
      # now attempt to fetch what looks like a valid radar ID
      printf '\n%s' "Attempting to fetch ${id} radar data: "
      # ensure we have recent list first
      get_radar_list & pid=${!}
      display_spinner ${pid}
      wait ${pid}; get_list_status=${?}
      if [[ ${get_list_status} -ne 0 ]]; then
        printf '%s\n' 'failed. Is the Internet connection up?'
        exit 4
      fi
      # is the ID on the list?
      if ! grep --quiet --fixed-strings "${id}" --line-regexp radar-IDs.list; then
        printf 'failed.\n'
        printf "\n'%s' %s\n%s\n\n" "${id}" "ID could not be found as an available radar image set." "Are you sure the ID is correct?"
        printf '%s\n\n' "Try 'bash ${0} radar list' to display a list of available IDs."
        exit 3
      else
        # everything fine, so pop in some pretty empty space
        printf '\n\n'
      fi

      # looking good, ensure storage is available
      mkdir --parents "${working_directory}/images/radar/${id}" || exit 2
      cd "${working_directory}/images/radar/${id}/" || exit 2

      # get the radar images
      # if we have a valid HH:MM globbing argument in ${3}, narrow the `wget` glob to that
      if [[ "${3}" =~ ^([01][0-9]|2[0-3]):([0-5][0-9]|[0-5]\?|\?[0-9]|\?\?)$ ]]; then
        # wrap `wget` in `flock` to lock the working directory so we don't get race condition when running this as a cronjob
        # if we get network problems with `wget`, its exit code should be 4 (in the wrapped flock command), otherwise if we encounter a problem with `flock`, exit 5
        # pass the `flock` exit code to display_flock_error() in order to either show a pretty message if encountering parallel fetching, otherwise fail silently
        # reject any "temporary" files, as in this context, these are images currently being written to disk at the origin and are incomplete
        # remove colon from globbing arg user input by using '//' parameter expansion
        # *** ! *** `wget` is weird because it writes file download progress to stderr, so explicitly redirect that here to stdout *** ! ***
        printf '%s %s %s\n\n' "Glob narrowed to select images from" "${3}" "UTC only."
        flock --conflict-exit-code 5 --nonblock --exclusive --no-fork "${working_directory}/images/radar/${id}" --command " \
          2>&1 wget --quiet --show-progress --progress=bar:force:noscroll --timestamping --continue --timeout=30 --tries=30 --random-wait --reject=tmp \
          ftp://ftp.bom.gov.au/anon/gen/radar/${id}.T.[0-9]*${3//:}.png || exit 4" || display_flock_error $?
      else
        # download all images
        # filename pattern on bom server is ID.T.YYYYMMDDHHMM, png file extension
        # this will traverse and fetch existing archive (i.e. whatever bom keeps on the server for 2 hours, for example)
        # *** ! *** `wget` is weird because it writes file download progress to stderr, so explicitly redirect that here to stdout *** ! ***
        flock --conflict-exit-code 5 --nonblock --exclusive --no-fork "${working_directory}/images/radar/${id}" --command " \
          2>&1 wget --quiet --show-progress --progress=bar:force:noscroll --timestamping --continue --timeout=30 --tries=30 --random-wait --reject=tmp \
          ftp://ftp.bom.gov.au/anon/gen/radar/${id}.T.[0-9]*.png || exit 4" || display_flock_error $?
      fi


      # get the background image layers if need be
      printf '\n%s\n' "Getting geographical layers:"
      mkdir --parents "${working_directory}/images/radar/${id}/layers" || exit 2
      cd "${working_directory}/images/radar/${id}/layers/" || exit 2
      # the second last characters of an ID denotes it's location set
      # so for example in IRD031, 03 = Wollongong NSW, 1=512km composite view, 2=256km, 3=128km, 4=64km
      #                in IRD03A, 03 = Wollongong NSW, A=rain per 6 minutes, B=per hour, C=since 9am, D=24hrs, I=doppler wind velocity
      # bom doesn't publish all the layers with their required IDs for A B C D and I sets so we need to do some processing here to get their backgrounds
      # one assumes this is done to save disk space? but not sure why
      # bom also doesn't publish background or layering for IDR00004 (the national rainfall radar), which is weird, so handle an exception for that
      # online it looks like they use the 'IDE00135.radar' satellite image
      # i.e. http://www.bom.gov.au/products/national_radar_sat.loop.shtml
      # waaargh, not sure why bom the gov is messy here?

      # so, if dealing with the national rainfall radar (IDR00004)
      if [[ "${id}" == 'IDR00004' ]]; then
        # hardcode getting a known static national background image
        # use the static one they use on http://www.bom.gov.au/products/national_radar_sat.loop.shtml
        # i.e. IDE00035 (note: *35* not *135*)
        # they don't publish that image in their ftp archive either (wtf?!) so grab it from the website
        # rename that image to the national rainfall radar ID, so we at least are keeping track of what we're trying to fix
        # does this seem a bit hacky and disorganised for an agency that runs on data?
        # also, we have to pretend to be a browser here, since bom discourages web scraping!
        curl \
          --output 'IDR00004.background.png' \
          --user-agent 'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:105.0) Gecko/20100101 Firefox/105.0' \
          --referer 'http://www.bom.gov.au/products/national_radar_sat.loop.shtml' \
          --url 'http://www.bom.gov.au/products/radar_transparencies/IDE00035.background.png' || exit 4

      # then if the ID ends in A B C D or I
      elif [[ "${id}" =~ [A-D|I]$ ]]; then
        # the rainfall (A to D) and doppler wind (I) sets all use 128km background, i.e. layers of view '3'
        # so strip off the last character of the ID and force the FTP pattern to be the '3' (128km) view by appending it to the pattern
        # *** ! *** `wget` is weird because it writes file download progress to stderr, so explicitly redirect that here to stdout *** ! ***
        2>&1 wget --quiet --show-progress --progress=bar:force:noscroll --timestamping --continue --timeout=30 --tries=30 --random-wait "ftp://ftp.bom.gov.au/anon/gen/radar_transparencies/${id%?}3*.png" || exit 4

      # none of the above exceptions have been met
      else
        # don't need to do anything special, so get the ID layers as they're published; phew!
        # *** ! *** `wget` is weird because it writes file download progress to stderr, so explicitly redirect that here to stdout *** ! ***
        2>&1 wget --quiet --show-progress --progress=bar:force:noscroll --timestamping --continue --timeout=30 --tries=30 --random-wait "ftp://ftp.bom.gov.au/anon/gen/radar_transparencies/${id}*.png" || exit 4
      fi

      # ensure radar image legend layers are available
      printf '\n%s\n' "Getting graph legends:"
      mkdir --parents "${working_directory}/images/radar/legend" || exit 2
      cd "${working_directory}/images/radar/legend" || exit 2
      # *** ! *** `wget` is weird because it writes file download progress to stderr, so explicitly redirect that here to stdout *** ! ***
      2>&1 wget --quiet --show-progress --progress=bar:force:noscroll --timestamping --continue --timeout=30 --tries=30 --random-wait "ftp://ftp.bom.gov.au/anon/gen/radar_transparencies/IDR.legend*.png" || exit 4

      # completed successfully, stop timer and display total runtime
      timer_stop=$(date +%s)
      printf '\n%s\n\n' 'Completed successfully.'
      printf '%s\n\n' "Total fetching time was $(display_pretty_timer $((timer_stop-timer_start)))."
    ;;
  esac
}

handle_timelapse_images() {
  case "${2}" in
    'list')
      init
      # get list of image sets that have been collected
      printf '%s' "Searching for collected images... "
      get_timelapse_list | less
      printf '\n'
    ;;

    ''|'help')
      # no option given, so display help
      display_timelapse_help
    ;;

    *)
      init
      # passed variable user input here
      # run sanitation and formatting tests
      handle_user_input "${1}" "${2}" # $2 being user input from command line
      # get resulting context, i.e. if after tests, ID is a radar or a satellite as we need to do different processing for each
      context="${id_type}"

      # now check to see if we have any collected images for this ID
      # this tests if directory exists and is not empty, while also collecting a list of files (if they exist) for use later
      # use a subshell so our changes to `shopt` are temporary
      # `nullglob` setting means patterns that don't match any filenames are simply expanded to **nothing** rather than remaining unexpanded
      # we need this so no matches return empty space rather than an unglobbed asterisk, i.e. literal *
      # `dotglob` setting means globbing to include hidden files, necessary for reliably ensuring a path is indeed empty or not
      # use `echo` to expand to print any matching filenames only, not an unspecified shell globbing wildcard which eventually expands to everything
      # also we don't need quoting in the array because we want things to intentionally wordsplit
      files=($(shopt -s nullglob dotglob; echo "${working_directory}/images/${context}/${id}/"*.*))
      # when evaluating the length of $files array with parameter expansion, if it's 0 then the path is empty/condition is true
      # this is a more robust way than using `-d` (which returns true if a directory exists even when empty)
      # or `find` (as it's exit codes aren't consistent with empty paths that exist, and not as flexible here, unless we use messy exec?)
      # this method of checking is also superior because we reduce processing later by already having matched files ready to go in an array
      if ! [[ -d "${working_directory}/images/${context}/${id}" && ${#files[@]} -ne 0 ]]; then
        printf "\n'%s' %s\n" "${id}" "might be a valid ${context} ID, but does not seem to have any collected images yet."
        printf '%s\n\n' "Try 'bash ${0} ${context} ${id}' to start collecting images first."
        exit 3
      fi

      # switch to the folder now we've checked the user input for it is legit
      cd "${working_directory}/images/${context}/${id}/" || exit 2

      # ensure we have a scratch storage ready for current conversion to be temporarily saved into
      scratch="$(mktemp --directory --tmpdir="${tmp}" .timelapse-XXXXXXXX)"
      # set up a counter for 'percentage complete' tracking in next steps
      count=1
      # set up arrays to capture exit codes from `convert` and `ffmpeg` during each iteration, as we'll test these later to check if any errors are encountered
      convert_result=()
      ffmpeg_result=()
      # set stopwatch to keep track of total run time for assembling timelapse, starting from now
      timer_start=$(date +%s)

      # prepare each image as video frames
        # if we're making a timelapse of satellite images, ensure we flatten each image to a jpeg, as tifs have multiple layers which `ffmpeg` doesn't like
        if [[ "${context}" == 'satellite' ]]; then
          # *** imagemagick defaults need to be tweaked from now on for dealing with the large canvas sizes of himawari satellite images ***
          # largest known satellite image sets are IDE0409 with 0.5km per pixel resolution: results in image sizes of 24444 x 16667 @ 96dpi, which is ~408 megapixels
          # default megapixel limit for imagemagick is 128MP, and so conversion crashes with defaults when dealing with IDE0409 (thanks for the bug report @matt_brown!)
          # set MAGICK_CONFIGURE_PATH to import bundled policy.xml settings to from .config folder to explicitly increase width and height limits, etc
          # documentation at: https://imagemagick.org/script/resources.php

          # now actually do the conversion
          for file in "${files[@]}"; do
            printf '%s %d%s ' "Flattening satellite images..." $((count * 100 / ${#files[@]})) '%'
            # get the name of the current file only by stripping off its path
            current_filename="${file##*/}"
            # tif files from bom have multiple layers, and if just using filenames, imagemagick splits those layers into multiple files which is unwanted
            # so use [0] after file name which `convert` interprets as "get the first layer only"
            # ensure we are converting to jpegs by removing current filename's extension and substituting .jpg using parameter expansion
            # also do `convert` quietly to avoid any warning messages that we might encounter about tif layers that are now irrelevant
            # capture the exit code of `convert` into its prepared array for success checking later
            convert -quiet -scale 1920x1080\> "${file}[0]" "${scratch}/${current_filename%.*}.jpg"; convert_result+=($?)
              # himawari satellite images have no timestamps on them, so if handling their IDs here, append that information to current frame
              # IDs that are currently known are in the range IDE004xx, i.e. 401 to 437 so if we get a match on that, add our own timestamp label
              # use the served file metadata parsed through `date` to make our timestamp
              # the text passed to `convert` to be created, is in the 'label' argument
              if [[ "${id}" =~ ^IDE004[0-3][0-9]$ ]]; then
                convert "${scratch}/${current_filename%.*}.jpg" \
                  -background black -fill white -font Ubuntu-Mono -pointsize 18 label:"$(date --utc --reference "${current_filename}")" \
                  -gravity center -append "${scratch}/${current_filename%.*}.jpg"; convert_result+=($?)
              fi
            # advance the progress meter
            ((count++))
            # return cursor to the start of the line
            printf '\r'
          done

        # if we're making a timelapse of a radar, assemble its layers
        elif [[ "${context}" == 'radar' ]]; then
          # order of layers: legend -> geographical background -> topography -> location names -> radar data range circle -> current rain radar data
          # determine what legend is required first, based on it's ID structure
            # if ID ends in a number, it's a rainfields data; use legend 0 (rain rate scale, light -> heavy)
            [[ "${id}" =~ [0-9]$ ]] && legend="${working_directory}/images/radar/legend/IDR.legend.0.png"
            # if ID ends in A B C or D then it's a rainfields data; use legend 1 (rainfall in mm)
            [[ "${id}" =~ [A-D]$ ]] && legend="${working_directory}/images/radar/legend/IDR.legend.1.png"
            # if ID ends in I it's doppler wind data; use legend 2 (colour codes for towards/away from radar)
            [[ "${id}" =~ I$ ]] && legend="${working_directory}/images/radar/legend/IDR.legend.2.png"

          # however, if the current radar ID is the national radar, it does not have topography, locations, or range layers so don't process them (eyeroll)
          # otherwise, it's a radar as "usual" so assemble those layers
          # such a messy bom
          if [[ "${id}" == 'IDR00004' ]]; then
            # the conversion loop should exclude layers that don't exist for national radar
            for file in "${files[@]}"; do
              printf '%s %d%s ' "Flattening radar image layers..." $((count * 100 / ${#files[@]})) '%'
              # do conversion quietly
              convert -quiet \
                "${legend}" \
                "layers/*.background.png" \
                "$file" -flatten "${scratch}/${file##*/}"; convert_result+=($?)
              # advance the progress meter
              ((count++))
              # return cursor to the start of the line
              printf '\r'
            done
          else
            # a radar as usual, so conversion loop should assemble known/desired layers
            for file in "${files[@]}"; do
              printf '%s %d%s ' "Flattening radar image layers..." $((count * 100 / ${#files[@]})) '%'
              convert -quiet \
                "${legend}" \
                "layers/*.background.png" \
                "layers/*.topography.png" \
                "layers/*.locations.png" \
                "layers/*.range.png" \
                "$file" -flatten "${scratch}/${file##*/}"; convert_result+=($?)
              ((count++))
              printf '\r'
            done
          fi
        fi

      # if conversion encountered any errors, stop here
        # arrays implicitly concatenate inside [[ ]] so use explicit * for expanding the array instead of @
        # `convert` only returns two exit codes: '0' for success as normal, or '1' for any failure
        # so, only need to check for the existence of '1' anywhere
        if [[ "${convert_result[*]}" =~ 1 ]]; then
          printf '\n\n%s\n%s\n\n' "Error(s) occurred during image preparation." "Creating timelapse failed. Stopping."
          exit 1
        fi

      # everything fine, so now get the first and last names of files we're timelapsing, for use in a moment to generate label for mp4 file
      first_file="${files[0]##*/}"
      last_file="${files[${#files[@]}-1]##*/}" # looks messy because to get last array item, we need total number of keys minus one
      # determine each file's creation date and time to discern timeframe of capture
      # utc is also useful as bom/generic weather seems to prefer that for consistency (although, bom not always)
      timelapse_from="$(date --utc '+%Y-%m-%d_%H%M' --reference "${first_file}")"
      timelapse_to="$(date --utc '+%Y-%m-%d_%H%M' --reference "${last_file}")"
      timelapse_file="${working_directory}/timelapse/[${id}] ${timelapse_from} to ${timelapse_to}.mp4"

      # ensure directory to store created timelapse exists
      mkdir --parents "${working_directory}/timelapse" || exit 2

      # now make mp4 video timelapse!
      printf '\n%s\n' "Making MP4... "
      # wait a short moment first for disk caching
      sleep 1
        # if we're making a timelapse of satellite images, ensure we flatten each image to a jpeg as tifs have multiple layers which `ffmpeg` doesn't like
        if [[ "${context}" == 'satellite' ]]; then
          # capture the exit code of `ffmpeg` into the prepared array for success checking later
          # `-vf` to add padding to avoid potential "height not divisible by 2" crashes
          # *** ! *** `ffmpeg` requires everything on one long line here, as some versions break when using backslashes between switches for some reason *** ! ***
          ffmpeg -r 25 -pattern_type glob -i "${scratch}/*.jpg" -vf "pad=ceil(iw/2)*2:ceil(ih/2)*2" "${timelapse_file}"; ffmpeg_result+=($?)

        # if we're making a timelapse of a radar, we use the assembled png files
        elif [[ "${context}" == 'radar' ]]; then
          # `-r 10` means essentially 10fps; 1 frame for radar image per ~5 minutes; so @10fps, 1 second of footage = ~1hr of radar data timelapsed
          # `-vf` to add padding to avoid potential "height not divisible by 2" crashes
          # generate timestamp based on first and last collected frames
          # *** ! *** `ffmpeg` requires everything on one long line here, as some versions break when using backslashes between switches for some reason *** ! ***
          ffmpeg -r 10 -pattern_type glob -i "${scratch}/*.png" -vf "pad=ceil(iw/2)*2:ceil(ih/2)*2" "${timelapse_file}"; ffmpeg_result+=($?)
        fi

      # test if all `ffmpeg` iterations were successful
        # use a subshell and set bash's Internal Field Separator to wordsplit the exit codes in ffmpeg_result with a plus sign instead of whitespace
        # then, parse the expanded array into `bc` with here-string, so the expanded array becomes 'var1+var2+var3' and so on, that `bc` can then sum ;)
        ffmpeg_success="$(IFS='+'; bc <<< "${ffmpeg_result[*]}")"
      if [[ "${ffmpeg_success}" -eq 0 ]]; then
        # after a successful timelapse is made, move the stored images folder to .archive and clean up the remaining folder once that's done
        # clean up is needed so an empty ID doesn't appear in the available timelapse listings once a successful timelapse has been made from its data
        printf '\n%s\n\n' "Timelapse video for ${id} ${context} successfully created."
        mkdir --parents "${working_directory}/images/.archive/${context}/${id}" || exit 2
        cd "${working_directory}" || exit 2
        mv --force "${working_directory}/images/${context}/${id}/"*.* "${working_directory}/images/.archive/${context}/${id}/" && rm --force --recursive "${working_directory}/images/${context}/${id}"
      else
        printf '\n\n%s\n\n' "Error(s) occurred while attempting to assemble timelapse video for ${id} ${context}. Stopping."
        exit 1
      fi

      # encountered no error exit, so stop timer and report how long we've been running
      timer_stop=$(date +%s)
      printf '%s\n\n' "Total processing time was $(display_pretty_timer $((timer_stop-timer_start)))."
      # open the timelapse video file in the user's preferred application
      ##xdg-open "${timelapse_file}"
    ;;
  esac
}

handle_reset_cleanup() {
  printf '\n%s\n' "This will delete *everything* (except rendered timelapses in /timelapse folder)."
  if handle_question "Are you sure you want to continue?"; then
    # yes, wipe out
    rm --force --recursive "${working_directory}/images" && printf '%s\n\n' "Cleanup successful."
  else
    printf '%s\n\n' "Stopping."
  fi
}

handle_update() {
  # quietly ensure we're at the last remote commit, to overwrite any local changes
  git reset --hard origin --quiet
  # pull latest code from remote
  # redirect `git pull` output to stderr wholesale so the update changes/response gets logged as part of xtrace
  if git pull --force 1>&2; then
    # quietly rebase to integrate and resync local to the remote branch
    # use `--force-rebase` to replay all commits, ovewriting any local changes and sync to remote
    git rebase --force-rebase --quiet
  else
    # problem encountered pulling code
    printf '%s\n' "Updating ${0} failed."
    exit 4
  fi
}

handle_debugging() {
  case "${2}" in
    'on')
      # turn on code debugging log
      # the control is determined by the existence of a file called 'debug' in .config folder
      if [[ -e "${working_directory}/.config/debug" ]]; then
        # setting file already exists, nothing to do
        printf '%s\n' "Code debugging log setting is already on. :)"
      else
        # create the file
        touch "${working_directory}/.config/debug"
        printf '%s\n' "Code debugging log now turned on. Thank you!"
      fi
    ;;

    'off')
      # turn off debuging and erase any existing logs
      printf '\n%s\n' "This will turn off debug logging and delete existing logs."
      if handle_question "Are you sure you want to continue?"; then
        # yes, wipe the logs and turn off debugging
        rm --force "${working_directory}/.config/debug" && rm --force "${logfile}" && printf '%s\n\n' "Code debugging log is off, and logs cleared."
      else
        printf '%s\n\n' "Stopping."
      fi
    ;;

    ''|'help')
      # no option given, so display help
      display_debug_help
    ;;
  esac
}



## runtime

# work out what to do from the first argument of user input
case "${1}" in
  'radar') handle_radar_images "$@";;
  'satellite') handle_satellite_images "$@";;
  'timelapse') handle_timelapse_images "$@";;
  'reset') handle_reset_cleanup;;
  'update') handle_update;;
  'debug') handle_debugging "$@";;
  'version') display_version;;
  'help') display_help;;
  '') display_help;;
  *)
    printf "%s: '%s'\n" "Invalid option" "${1}"
    printf '%s\n' "Try 'bash ${0} help' for more information."
    exit 3
  ;;
esac

# if all runtime paths are traversed without a problem, exit successfully
# this 'exit' also trips off trap for garbage collection
exit 0
